"""
åœ¨check_excelä¹‹åï¼Œè¾“å…¥æ˜¯ UploadInfo å¯¹è±¡

æœ€æ ¸å¿ƒçš„éƒ¨åˆ†æ˜¯ï¼Œç»™å®šä¸€ä¸ªdetailçš„pathï¼Œè®¡ç®—æ‰€æœ‰çš„åˆ†ç»„æ±‡æ€»ç»“æœ
"""
import typing

import pandas as pd
import os

from lwx_project.scene.monthly_communication_data.check_excel import UploadInfo
from lwx_project.scene.monthly_communication_data.const import DETAIL_PATH, IMPORTANT_PATH, TEMPLATE_PATH
from lwx_project.utils.file import copy_file
from lwx_project.utils.time_cost import time_cost


def cal_and_merge(upload_info: UploadInfo, code_rules_dict, after_one_done_callback):
    # 1. è®¡ç®—æ‰€æœ‰çš„ç»“æœ
    caled_result_list = detail_group_by(
        excel_path_list=upload_info.upload_tuanxian_month_dict.values,
        code_map=code_rules_dict,
        after_one_done_callback=after_one_done_callback,
    )

    # 2. å¡«å……æŒ‡å®šä½ç½®
    caled_path = merge_caled_result(upload_info, caled_result_list)
    return caled_path


@time_cost
def merge_caled_result(upload_info: UploadInfo, result_list):
    # 1 æ‰¾åˆ°å¯¹åº”çš„æ¨¡æ¿ï¼Œå¦‚æœæ²¡æœ‰æ‹·è´ä¸€ä¸ªæ–°çš„å‡ºæ¥
    # 2 å°†ç»“æœé€ä¸€å¡«å……è¿›å»
    # 3 è¿”å›æ–°çš„ç»“æœ
    target_year_dir = os.path.join(IMPORTANT_PATH, str(upload_info.year))
    
    # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
    os.makedirs(target_year_dir, exist_ok=True)
    
    caled_paths = []

    # å°†è®¡ç®—ç»“æœå¡«å……æ¨¡æ¿
    for month, result_df in zip(upload_info.upload_tuanxian_month_dict.keys(), result_list):
        this_path = os.path.join(target_year_dir, str(month)+"æœˆåŒä¸šäº¤æµæ•°æ®.xlsx")
        # æ‹·è´æ¨¡æ¿
        copy_file(TEMPLATE_PATH, this_path)
        
        # ä½¿ç”¨openpyxlæ¥æ“ä½œExcelï¼Œä¿ç•™åŸæœ‰æ ¼å¼
        from openpyxl import load_workbook
        
        try:
            # åŠ è½½å·¥ä½œç°¿
            wb = load_workbook(this_path)
            # è·å–ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
            ws = wb.active
            
            # åˆ›å»ºåˆ†å…¬å¸åˆ°è¡Œå·çš„æ˜ å°„
            company_to_row = {}
            # ä»ç¬¬4è¡Œå¼€å§‹æŸ¥æ‰¾åˆ†å…¬å¸ï¼ˆæ¨¡æ¿å‰3è¡Œæ˜¯æ ‡é¢˜ï¼‰
            for row in range(4, ws.max_row + 1):
                company_cell = ws.cell(row=row, column=1)
                company_name = company_cell.value
                if company_name and isinstance(company_name, str):
                    company_to_row[company_name] = row
            
            # å°†result_dfä¸­çš„æ•°æ®å¡«å……åˆ°æ¨¡æ¿ä¸­
            for _, row_data in result_df.iterrows():
                company_name = row_data['åˆ†å…¬å¸']
                if company_name in company_to_row:
                    row_num = company_to_row[company_name]
                    
                    # å¡«å……æ•°æ®ï¼Œä¿ç•™åŸæœ‰æ ¼å¼
                    # çŸ­æœŸï¼š<= 1å¹´
                    # æ„å¤–é™© - ç¬¬2åˆ—
                    ws.cell(row=row_num, column=2).value = row_data['æ„å¤–é™©']
                    # å¥åº·é™© - ç¬¬3åˆ—
                    ws.cell(row=row_num, column=3).value = row_data['å¥åº·é™©']
                    # å¯¿é™© - ç¬¬4åˆ—
                    ws.cell(row=row_num, column=4).value = row_data['å¯¿é™©']
                    # åŒ»ç–—åŸºé‡‘ - ç¬¬5åˆ—
                    ws.cell(row=row_num, column=5).value = row_data['åŒ»ç–—åŸºé‡‘']
                    # åˆè®¡ - ç¬¬6åˆ—
                    ws.cell(row=row_num, column=6).value = row_data['åˆè®¡']
                    # é•¿æœŸï¼š>1å¹´
                    # é•¿æœŸæ„å¤–	é•¿æœŸå¥åº·é™©	é•¿æœŸå¯¿é™© éƒ½æ˜¯0ï¼ˆ12ã€13ã€14æ˜¯å½“æœˆï¼Œ17ã€18ã€19æ˜¯ç´¯è®¡å…¨å¹´
                    ws.cell(row=row_num, column=12).value = 0
                    ws.cell(row=row_num, column=13).value = 0
                    ws.cell(row=row_num, column=14).value = 0
                    ws.cell(row=row_num, column=17).value = 0
                    ws.cell(row=row_num, column=18).value = 0
                    ws.cell(row=row_num, column=19).value = 0

                    # å¹´é‡‘é™© - ç¬¬15åˆ—å’Œç¬¬16åˆ—
                    ws.cell(row=row_num, column=15).value = row_data['å¹´é‡‘é™©']
                    ws.cell(row=row_num, column=16).value = row_data['å¹´é‡‘é™©']
            
            # ä¿å­˜å·¥ä½œç°¿
            wb.save(this_path)
            caled_paths.append(this_path)
            print(f"æˆåŠŸå¡«å…… {this_path} çš„æ•°æ®")
        except Exception as e:
            print(f"å¡«å…… {this_path} çš„æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            continue

    # å°†æ±‡æ€»ç»“æœå¡«å……æ¨¡æ¿
    need_cal_min_month = min(upload_info.upload_tuanxian_month_dict.keys())
    files = sorted(os.listdir(target_year_dir), key=lambda x: int(x.split("æœˆ")[0]))
    for file in files:  # æŒ‰é¡ºåºäº†
        this_path = os.path.join(target_year_dir, file)
        this_parts = file.split("æœˆ")
        this_month = int(this_parts[0])
        path_suffix = "æœˆ" + this_parts[1]
        if this_month >= need_cal_min_month:  # å¦‚æœæœ‰æœˆä»½è¿›è¡Œè®¡ç®—äº†ï¼Œé‚£ä¹ˆä»è¿™ä¸ªæœˆä»½å¼€å§‹ï¼Œåé¢çš„æœˆä»½éƒ½éœ€è¦é‡æ–°æ±‡æ€»
            # éœ€è¦å°†è¿™äº› this_path ä¸‹åé¢æœˆä»½çš„å…¨å¹´æ•°æ®é‡æ–°æ±‡æ€»è®¡ç®—
            if this_month == 1:  # è¯´æ˜è¦ä»1æœˆé‡æ–°ç®—
                # å°†1æœˆçš„ï¼Œå½“æœˆæ•°æ®ï¼Œç›´æ¥è¡¥å……ä¸ºå…¨å¹´çš„ï¼Œåªè€ƒè™‘4åˆ°26è¡Œ
                # ç¬¬2ã€3ã€4ã€5ã€6åˆ—ï¼Œåˆ†åˆ«å¯¹åº”7ã€8ã€9ã€10ã€11åˆ—
                # ç¬¬12ã€13ã€14ã€15ã€16åˆ—ï¼Œåˆ†åˆ«å¯¹åº”17ã€18ã€19ã€20ã€21åˆ—
                # TODO
            else:
                # å…¶ä»–æœˆä»½ï¼Œåªéœ€è¦æ‰¾åˆ°ä¸Šä¸€ä¸ªæœˆçš„æ±‡æ€»å€¼ï¼ŒåŠ åˆ°è¿™ä¸ªæœˆ
                last_file = f"{this_month-1}{path_suffix}"
                last_month_path = os.path.join(target_year_dir, last_file)
                # åœ¨ last month pathä¸­ï¼Œæ‰¾åˆ° 7ã€8ã€9ã€10ã€11 åˆ—å¯¹åº”æˆªæ­¢å½“å‰æœˆçš„æ±‡æ€»æ•°æ®
                #


    # è¿”å›æœ€åä¸€ä¸ªå¤„ç†çš„æ–‡ä»¶è·¯å¾„ï¼ˆæˆ–è€…æ‰€æœ‰è·¯å¾„çš„åˆ—è¡¨ï¼‰
    return caled_paths[-1] if caled_paths else None


# æ ¸å¿ƒçš„åˆ†ç»„è®¡ç®—è¿‡ç¨‹
@time_cost
def detail_group_by(excel_path_list, code_map: dict, after_one_done_callback: typing.Callable[[int], None]=None):
    """
    excel_path_list: excelçš„ç»å¯¹è·¯å¾„çš„list
    code_map: è®¡ç®—æ±‡æ€»ç»“æœæ—¶éœ€è¦å¿½ç•¥æˆ–å¢åŠ çš„ä»£ç ï¼Œè´Ÿæ•°ä¸ºå¿½ç•¥ï¼Œæ­£æ•°ä¸ºå¢åŠ ï¼Œç»å¯¹å€¼ä¸ºä»£ç 
        {
            "æ„å¤–é™©": [],
            "å¥åº·é™©": [-7824],
            "å¯¿é™©": [],
            "åŒ»ç–—åŸºé‡‘": [+7824, +7854],
            "å¹´é‡‘é™©": [-2801]
        }

    é’ˆå¯¹æ¯ä¸€ä¸ªexcelæ‰§è¡Œä¸‹åˆ—è¿‡ç¨‹ï¼ˆæ³¨æ„è¿™é‡Œçš„æ¯ä¸ªexcelå¯èƒ½åœ¨10mbå·¦å³ï¼Œéœ€è¦æ³¨æ„æ€§èƒ½ï¼‰ï¼š
        1. è¯»å–ç¬¬ä¸€ä¸ªsheet
        2. ä»…ä¿ç•™ä¸‰åˆ—ï¼ˆç¬¬ä¸€è¡Œå°±æ˜¯åˆ—åï¼‰
            â€æœºæ„åç§°â€ã€â€œé™©ç§ä»£ç â€ã€â€œä¿è´¹æ”¶å…¥/æ”¯å‡ºï¼ˆå«ç¨ï¼‰â€
        3. æå–ç»“æ„åç§°çš„å‰ä¸¤ä¸ªå­—ç¬¦ï¼Œå¦‚æœå‰ä¸¤ä¸ªå­—ç¬¦ä¸ºâ€œé»‘é¾™â€ï¼Œå°±è¡¥æˆ â€œé»‘é¾™æ±Ÿâ€ï¼Œå˜æˆâ€œåˆ†å…¬å¸â€åˆ—
            æ­¤æ—¶å¯ä»¥åˆ æ‰æœºæ„åç§°åˆ—
        4. æŒ‰ç…§â€œåˆ†å…¬å¸â€åˆ—è¿›è¡Œgroupbyè®¡ç®—
            æ„å¤–é™©ï¼šé™©ç§ä»£ç  ä»¥68å¼€å¤´ çš„è¡Œ
            å¥åº·é™©ï¼šé™©ç§ä»£ç  ä»¥78å¼€å¤´ï¼Œä½†æ˜¯ä¸åŒ…æ‹¬7824 çš„è¡Œ
                è¿™é‡Œçš„7824æ˜¯ç”± code_map å˜é‡å†³å®šçš„ï¼ŒåŠ¨æ€ä¼ å…¥çš„ï¼Œ7824åªæ˜¯ä¸¾ä¸ªä¾‹å­
            å¯¿é™©: æ„å¤–é™©ï¼šé™©ç§ä»£ç  ä»¥18å¼€å¤´ çš„è¡Œ
            åŒ»ç–—åŸºé‡‘ï¼šé™©ç§ä»£ç  æ˜¯7824 çš„è¡Œ
                è¿™é‡Œçš„7824æ˜¯ç”± code_map å˜é‡å†³å®šçš„ï¼ŒåŠ¨æ€ä¼ å…¥çš„ï¼Œ7824åªæ˜¯ä¸¾ä¸ªä¾‹å­
            åˆè®¡ï¼šä¸Šè¿°å››ç§ä¿é™©çš„åˆè®¡
            è®¡ç®—ä¸Šè¿°å››ç§ä¿é™©çš„ä»·æ ¼ï¼šå³ æ±‚å’Œ ä¿è´¹æ”¶å…¥/æ”¯å‡ºï¼ˆå«ç¨ï¼‰ åˆ—
                å³æ¯ä¸ªåˆ†å…¬å¸éœ€è¦æŒ‰ç…§å¯¹åº”æ¡ä»¶ç­›é€‰åï¼Œå¯¹ ä¿è´¹æ”¶å…¥/æ”¯å‡ºï¼ˆå«ç¨ï¼‰ åˆ—æ±‚å’Œ

            å†å¢åŠ ä¸€ä¸ªå¹´é‡‘é™©ï¼ˆç®—åˆè®¡æ—¶ä¸è€ƒè™‘ï¼‰
                28å¼€å¤´ï¼Œä¸è€ƒè™‘2801
        5. æœ€ç»ˆç”Ÿæˆçš„è¡¨æ ¼å°±æ˜¯ï¼Œç¬¬ä¸€åˆ—æ˜¯groupbyçš„åˆ†å…¬å¸ï¼Œåé¢6åˆ—æ˜¯å¯¹åº”çš„å››ç§ä¿é™©çš„æ±‡æ€»ä»¥åŠåˆè®¡ å†åŠ å¹´é‡‘é™©
            å…±7åˆ—
    æ¯ä¸ªexcelè¿”å›6åˆ—çš„ä¸€ä¸ªdataframe
    """
    result_dfs = []
    
    # éªŒè¯excel_path_listä¸ä¸ºç©º
    if not excel_path_list:
        return result_dfs
    
    # éªŒè¯code_mapçš„åŸºæœ¬ç»“æ„
    required_keys = ["æ„å¤–é™©", "å¥åº·é™©", "å¯¿é™©", "åŒ»ç–—åŸºé‡‘"]
    for key in required_keys:
        if key not in code_map:
            code_map[key] = []
    
    for index, excel_path in enumerate(excel_path_list):
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(excel_path):
                print(f"è­¦å‘Šï¼šæ–‡ä»¶ä¸å­˜åœ¨: {excel_path}")
                continue
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºExcelæ–‡ä»¶
            if not (excel_path.endswith('.xlsx') or excel_path.endswith('.xls')):
                print(f"è­¦å‘Šï¼šæ–‡ä»¶ä¸æ˜¯Excelæ–‡ä»¶: {excel_path}")
                continue
            
            # è¯»å–Excelæ–‡ä»¶çš„ç¬¬ä¸€ä¸ªsheetï¼Œä¼˜åŒ–æ€§èƒ½
            df = pd.read_excel(excel_path, sheet_name=0, engine='openpyxl', usecols=None)
            
            # åªä¿ç•™éœ€è¦çš„ä¸‰åˆ—
            columns_to_keep = [
                'æœºæ„åç§°',  # å¯èƒ½éœ€è¦å¤„ç†å…¨è§’å¼•å·
                'é™©ç§ä»£ç ',
                'ä¿è´¹æ”¶å…¥/æ”¯å‡ºï¼ˆå«ç¨ï¼‰'
            ]
            
            # å¤„ç†å¯èƒ½çš„åˆ—åä¸ä¸€è‡´é—®é¢˜
            actual_columns = []
            for col in columns_to_keep:
                found = False
                for actual_col in df.columns:
                    # å¤„ç†å¯èƒ½çš„å…¨è§’å­—ç¬¦å’Œç©ºæ ¼é—®é¢˜
                    clean_actual_col = ''.join(char for char in str(actual_col) if char.isprintable()).strip()
                    clean_target_col = ''.join(char for char in col if char.isprintable()).strip()
                    
                    if clean_target_col in clean_actual_col or clean_actual_col in clean_target_col:
                        actual_columns.append(actual_col)
                        found = True
                        break
                if not found:
                    # å¦‚æœæ‰¾ä¸åˆ°å®Œå…¨åŒ¹é…çš„åˆ—ï¼Œå°è¯•æ‰¾åˆ°æœ€ç›¸ä¼¼çš„
                    for actual_col in df.columns:
                        clean_actual_col = ''.join(char for char in str(actual_col) if char.isprintable()).strip()
                        if any(keyword in clean_actual_col for keyword in ['æœºæ„', 'é™©ç§', 'ä¿è´¹']):
                            actual_columns.append(actual_col)
                            found = True
                            break
                if not found:
                    raise ValueError(f"åœ¨Excelæ–‡ä»¶ä¸­æ‰¾ä¸åˆ°åˆ—: {col}")
            
            # é‡å‘½ååˆ—ä»¥ä¾¿åç»­å¤„ç†
            df = df[actual_columns].copy()
            df.columns = columns_to_keep
            
            # åˆ›å»º"åˆ†å…¬å¸"åˆ—
            def process_company_name(name):
                if isinstance(name, str):
                    if len(name) >= 2:
                        first_two = name[:2]
                        if first_two == 'é»‘é¾™':
                            return 'é»‘é¾™æ±Ÿ'
                        return first_two
                return str(name)[:2] if isinstance(name, str) else str(name)
            
            df['åˆ†å…¬å¸'] = df['æœºæ„åç§°'].apply(process_company_name)
            
            # ç§»é™¤"æœºæ„åç§°"åˆ—
            df = df.drop('æœºæ„åç§°', axis=1)
            
            # ç¡®ä¿"é™©ç§ä»£ç "æ˜¯å­—ç¬¦ä¸²ç±»å‹
            df['é™©ç§ä»£ç '] = df['é™©ç§ä»£ç '].astype(str)
            
            # ç¡®ä¿"ä¿è´¹æ”¶å…¥/æ”¯å‡ºï¼ˆå«ç¨ï¼‰"æ˜¯æ•°å€¼ç±»å‹
            df['ä¿è´¹æ”¶å…¥/æ”¯å‡ºï¼ˆå«ç¨ï¼‰'] = pd.to_numeric(df['ä¿è´¹æ”¶å…¥/æ”¯å‡ºï¼ˆå«ç¨ï¼‰'], errors='coerce')
            df = df.dropna(subset=['ä¿è´¹æ”¶å…¥/æ”¯å‡ºï¼ˆå«ç¨ï¼‰'])
            
            # å‡†å¤‡åˆ†ç»„è®¡ç®—
            grouped = df.groupby('åˆ†å…¬å¸')
            result_df = pd.DataFrame()
            result_df['åˆ†å…¬å¸'] = list(grouped.groups.keys())
            
            # è®¡ç®—å„ç§ä¿é™©ç±»å‹çš„ä¿è´¹æ€»å’Œ
            
            # 1. æ„å¤–é™©è®¡ç®—
            # åŸºç¡€æ¡ä»¶ï¼šé™©ç§ä»£ç å¿…é¡»ä»¥68å¼€å¤´
            # ä»code_map['æ„å¤–é™©']ä¸­è·å–æ‰€æœ‰æ­£æ•°ä»£ç ï¼ˆè¡¨ç¤ºé¢å¤–åŒ…å«çš„ä»£ç ï¼‰å’Œè´Ÿæ•°ä»£ç ï¼ˆè¡¨ç¤ºè¦æ’é™¤çš„ä»£ç ï¼‰
            include_accident_codes = [str(abs(code)) for code in code_map.get('æ„å¤–é™©', []) if code > 0]
            exclude_accident_codes = [str(abs(code)) for code in code_map.get('æ„å¤–é™©', []) if code < 0]
            
            accident_insurance = grouped.apply(
                lambda x: x[
                    # å¿…é¡»æ»¡è¶³åŸºç¡€æ¡ä»¶ï¼šä»¥68å¼€å¤´
                    (x['é™©ç§ä»£ç '].str.startswith('68', na=False)) & 
                    # é¢å¤–åŒ…å«çš„ä»£ç ï¼ˆå¦‚æœæœ‰ï¼‰
                    ((len(include_accident_codes) == 0) | (x['é™©ç§ä»£ç '].isin(include_accident_codes))) & 
                    # æ’é™¤æŒ‡å®šçš„ä»£ç 
                    (~x['é™©ç§ä»£ç '].isin(exclude_accident_codes))
                ]['ä¿è´¹æ”¶å…¥/æ”¯å‡ºï¼ˆå«ç¨ï¼‰'].sum()
            )
            
            # 2. å¥åº·é™©è®¡ç®—
            # åŸºç¡€æ¡ä»¶ï¼šé™©ç§ä»£ç å¿…é¡»ä»¥78å¼€å¤´
            # ä»code_map['å¥åº·é™©']ä¸­è·å–æ‰€æœ‰æ­£æ•°ä»£ç ï¼ˆè¡¨ç¤ºé¢å¤–åŒ…å«çš„ä»£ç ï¼‰å’Œè´Ÿæ•°ä»£ç ï¼ˆè¡¨ç¤ºè¦æ’é™¤çš„ä»£ç ï¼‰
            include_health_codes = [str(abs(code)) for code in code_map.get('å¥åº·é™©', []) if code > 0]
            exclude_health_codes = [str(abs(code)) for code in code_map.get('å¥åº·é™©', []) if code < 0]
            
            health_insurance = grouped.apply(
                lambda x: x[
                    # å¿…é¡»æ»¡è¶³åŸºç¡€æ¡ä»¶ï¼šä»¥78å¼€å¤´
                    (x['é™©ç§ä»£ç '].str.startswith('78', na=False)) & 
                    # é¢å¤–åŒ…å«çš„ä»£ç ï¼ˆå¦‚æœæœ‰ï¼‰
                    ((len(include_health_codes) == 0) | (x['é™©ç§ä»£ç '].isin(include_health_codes))) & 
                    # æ’é™¤æŒ‡å®šçš„ä»£ç 
                    (~x['é™©ç§ä»£ç '].isin(exclude_health_codes))
                ]['ä¿è´¹æ”¶å…¥/æ”¯å‡ºï¼ˆå«ç¨ï¼‰'].sum()
            )
            
            # 3. å¯¿é™©è®¡ç®—
            # åŸºç¡€æ¡ä»¶ï¼šé™©ç§ä»£ç å¿…é¡»ä»¥18å¼€å¤´
            # ä»code_map['å¯¿é™©']ä¸­è·å–æ‰€æœ‰æ­£æ•°ä»£ç ï¼ˆè¡¨ç¤ºé¢å¤–åŒ…å«çš„ä»£ç ï¼‰å’Œè´Ÿæ•°ä»£ç ï¼ˆè¡¨ç¤ºè¦æ’é™¤çš„ä»£ç ï¼‰
            include_life_codes = [str(abs(code)) for code in code_map.get('å¯¿é™©', []) if code > 0]
            exclude_life_codes = [str(abs(code)) for code in code_map.get('å¯¿é™©', []) if code < 0]
            
            life_insurance = grouped.apply(
                lambda x: x[
                    # å¿…é¡»æ»¡è¶³åŸºç¡€æ¡ä»¶ï¼šä»¥18å¼€å¤´
                    (x['é™©ç§ä»£ç '].str.startswith('18', na=False)) & 
                    # é¢å¤–åŒ…å«çš„ä»£ç ï¼ˆå¦‚æœæœ‰ï¼‰
                    ((len(include_life_codes) == 0) | (x['é™©ç§ä»£ç '].isin(include_life_codes))) & 
                    # æ’é™¤æŒ‡å®šçš„ä»£ç 
                    (~x['é™©ç§ä»£ç '].isin(exclude_life_codes))
                ]['ä¿è´¹æ”¶å…¥/æ”¯å‡ºï¼ˆå«ç¨ï¼‰'].sum()
            )
            
            # 4. åŒ»ç–—åŸºé‡‘è®¡ç®—
            # ä»code_map['åŒ»ç–—åŸºé‡‘']ä¸­è·å–æ‰€æœ‰æ­£æ•°ä»£ç ï¼ˆè¡¨ç¤ºè¦åŒ…å«çš„ä»£ç ï¼‰å’Œè´Ÿæ•°ä»£ç ï¼ˆè¡¨ç¤ºè¦æ’é™¤çš„ä»£ç ï¼‰
            include_medical_codes = [str(abs(code)) for code in code_map.get('åŒ»ç–—åŸºé‡‘', []) if code > 0]
            exclude_medical_codes = [str(abs(code)) for code in code_map.get('åŒ»ç–—åŸºé‡‘', []) if code < 0]
            
            medical_fund = grouped.apply(
                lambda x: x[
                    # å¿…é¡»æ»¡è¶³åŒ…å«æ¡ä»¶
                    (x['é™©ç§ä»£ç '].isin(include_medical_codes)) & 
                    # æ’é™¤æŒ‡å®šçš„ä»£ç 
                    (~x['é™©ç§ä»£ç '].isin(exclude_medical_codes))
                ]['ä¿è´¹æ”¶å…¥/æ”¯å‡ºï¼ˆå«ç¨ï¼‰'].sum()
            )
            
            # è®¡ç®—åˆè®¡
            total = accident_insurance + health_insurance + life_insurance + medical_fund

            # 5. å¹´é‡‘é™©ï¼ˆéœ€è¦å•ç‹¬ç®—åˆè®¡ï¼Œä¸å’Œå…¶ä»–ç±»å‹ä¸€èµ·ï¼‰
            include_annu_codes = [str(abs(code)) for code in code_map.get('å¹´é‡‘é™©', []) if code > 0]
            exclude_annu_codes = [str(abs(code)) for code in code_map.get('å¹´é‡‘é™©', []) if code < 0]

            annu_fund = grouped.apply(
                lambda x: x[
                    # å¿…é¡»æ»¡è¶³åŸºç¡€æ¡ä»¶ï¼šä»¥28å¼€å¤´
                    (x['é™©ç§ä»£ç '].str.startswith('28', na=False)) &
                    # é¢å¤–åŒ…å«çš„ä»£ç ï¼ˆå¦‚æœæœ‰ï¼‰
                    ((len(include_annu_codes) == 0) | (x['é™©ç§ä»£ç '].isin(include_annu_codes))) &
                    # æ’é™¤æŒ‡å®šçš„ä»£ç 
                    (~x['é™©ç§ä»£ç '].isin(exclude_annu_codes))
                    ]['ä¿è´¹æ”¶å…¥/æ”¯å‡ºï¼ˆå«ç¨ï¼‰'].sum()
            )
            
            # å°†è®¡ç®—ç»“æœæ·»åŠ åˆ°ç»“æœDataFrame
            result_df = result_df.set_index('åˆ†å…¬å¸')
            result_df['æ„å¤–é™©'] = accident_insurance
            result_df['å¥åº·é™©'] = health_insurance
            result_df['å¯¿é™©'] = life_insurance
            result_df['åŒ»ç–—åŸºé‡‘'] = medical_fund
            result_df['åˆè®¡'] = total
            result_df['å¹´é‡‘é™©'] = annu_fund

            # é‡ç½®ç´¢å¼•ï¼Œä½¿åˆ†å…¬å¸æˆä¸ºæ™®é€šåˆ—
            result_df = result_df.reset_index()
            
            # å¡«å……å¯èƒ½çš„NaNå€¼ä¸º0
            result_df = result_df.fillna(0)
            
            result_dfs.append(result_df)
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {excel_path} æ—¶å‡ºé”™: {str(e)}")
            continue
        finally:
            if after_one_done_callback is not None:
                after_one_done_callback(index)
    return result_dfs

# â›³ ğŸ†•â­
if __name__ == '__main__':
    upload_info_ = UploadInfo(
        year=2025,
        upload_tuanxian_month_dict = {6: DETAIL_PATH},
        important_month_dict={},
        officer_path = None,
    )

    result_list_ = detail_group_by([DETAIL_PATH],{
            "æ„å¤–é™©": [],
            "å¥åº·é™©": [-7824, -7854],  # åé¢å¯èƒ½åŠ¨æ€å˜
            "å¯¿é™©": [],
            "åŒ»ç–—åŸºé‡‘": [+7824, +7854],  # åé¢å¯èƒ½åŠ¨æ€å˜
            "å¹´é‡‘é™©": [-2801],
        })

    merge_caled_result(upload_info_, result_list_)
    print()